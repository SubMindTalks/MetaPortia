import os
import yaml
from pathlib import Path

class ProjectInitializer:
    def __init__(self, root_dir="PortiaMeta"):
        self.root_dir = Path(root_dir)
        self.structure = {
            "data": {
                "repos": {},
                "analysis_results": {},
                "README.md": self._data_readme_content()
            },
            "grammars": {
                "language_v1.bnf": self._grammar_v1_content(),
                "language_v2.bnf": self._grammar_v2_content(),
                "README.md": self._grammar_readme_content()
            },
            "src": {
                "github_fetcher.py": self._github_fetcher_content(),
                "code_analysis.py": self._code_analysis_content(),
                "visualization.py": self._visualization_content(),
                "code_generator.py": self._code_generator_content(),
                "lexer.py": self._lexer_content(),
                "parser.py": self._parser_content(),
                "transformer.py": self._transformer_content(),
                "utils.py": self._utils_content(),
                "__init__.py": "# PortiaMeta package\n",
                "main.py": self._main_content()
            },
            "tests": {
                "test_github_fetcher.py": self._test_github_fetcher_content(),
                "test_code_analysis.py": self._test_code_analysis_content(),
                "test_visualization.py": self._test_visualization_content(),
                "test_code_generator.py": self._test_code_generator_content(),
                "test_transformer.py": self._test_transformer_content()
            },
            "examples": {
                "sample_code.dsl": self._sample_dsl_content(),
                "README.md": self._examples_readme_content()
            }
        }
        self.root_files = {
            ".gitignore": self._gitignore_content(),
            "README.md": self._main_readme_content(),
            "requirements.txt": self._requirements_content(),
            "config.yaml": self._config_content()
        }

    def create_project_structure(self):
        """Create the project directory structure and files."""
        print(f"Creating project structure in {self.root_dir}...")
        
        # Create root directory if it doesn't exist
        self.root_dir.mkdir(exist_ok=True)
        
        # Create directory structure and files
        self._create_structure(self.structure, self.root_dir)
        
        # Create root files
        for filename, content in self.root_files.items():
            file_path = self.root_dir / filename
            self._write_file(file_path, content)

        print("Project structure created successfully!")

    def _create_structure(self, structure, current_path):
        """Recursively create directory structure and files."""
        for name, content in structure.items():
            path = current_path / name
            if isinstance(content, dict):
                path.mkdir(exist_ok=True)
                self._create_structure(content, path)
            else:
                self._write_file(path, content)

    @staticmethod
    def _write_file(path, content):
        """Write content to file, creating parent directories if needed."""
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(content)

    # File content definitions
    def _data_readme_content(self):
        return """# Data Directory

This directory contains all data used and generated by the PortiaMeta project:

- `/repos`: Local clones of analyzed GitHub repositories
- `/analysis_results`: Output from code analysis pipelines

Note: This directory is git-ignored except for this README."""

    def _grammar_v1_content(self):
        return """# PortiaMeta DSL Grammar v1

# Top-level constructs
program        ::= statement*
statement      ::= macro_def | macro_call | code_block

# Macro definitions
macro_def      ::= "macro" IDENTIFIER "(" param_list ")" ":" NEWLINE INDENT body DEDENT
param_list     ::= (IDENTIFIER ("," IDENTIFIER)*)?
body           ::= statement+

# Macro calls
macro_call     ::= "$" IDENTIFIER "(" arg_list ")"
arg_list       ::= (expression ("," expression)*)?

# Code blocks and expressions
code_block     ::= (!/macro|\\$/ .)+
expression     ::= IDENTIFIER | STRING | NUMBER | macro_call

# Lexical rules
IDENTIFIER     ::= [a-zA-Z_][a-zA-Z0-9_]*
STRING         ::= '"' (/[^"\\]/ | "\\" .)* '"'
NUMBER         ::= [0-9]+ ("." [0-9]+)?"""

    def _grammar_v2_content(self):
        return """# PortiaMeta DSL Grammar v2 (Extended)

# Added support for expression macros and pattern matching

program        ::= statement*
statement      ::= macro_def | expr_macro_def | macro_call | code_block

# Expression macro definitions
expr_macro_def ::= "expr_macro" IDENTIFIER "(" param_list ")" ":" NEWLINE INDENT body DEDENT

# Pattern matching extensions
pattern_match  ::= "match" expression ":" NEWLINE INDENT case+ DEDENT
case           ::= "case" pattern ("if" expression)? ":" NEWLINE INDENT statement+ DEDENT
pattern        ::= IDENTIFIER | literal | struct_pattern | "_"
struct_pattern ::= "(" pattern ("," pattern)* ")" | "[" pattern ("," pattern)* "]"

# Rest of the grammar remains the same as v1..."""

    def _grammar_readme_content(self):
        return """# Grammar Definitions

This directory contains EBNF grammar definitions for the PortiaMeta DSL:

- `language_v1.bnf`: Base grammar with core macro functionality
- `language_v2.bnf`: Extended grammar with pattern matching and expression macros

Each version is documented with examples in the examples directory."""

    def _main_content(self):
        return """from pathlib import Path
from .github_fetcher import GitHubFetcher
from .code_analysis import CodeAnalyzer
from .code_generator import CodeGenerator
from .utils import load_config

def main():
    config = load_config()
    
    # Initialize components
    fetcher = GitHubFetcher(config)
    analyzer = CodeAnalyzer(config)
    generator = CodeGenerator(config)
    
    # Main processing pipeline
    repos = fetcher.fetch_repositories()
    patterns = analyzer.analyze_repositories(repos)
    generator.generate_code(patterns)

if __name__ == "__main__":
    main()"""

    def _github_fetcher_content(self):
        return """import github
from pathlib import Path
from typing import List, Dict

class GitHubFetcher:
    def __init__(self, config: Dict):
        self.config = config
        self.api = github.Github(config['github_token'])
        
    def fetch_repositories(self) -> List[Path]:
        \"\"\"Fetch relevant repositories based on config criteria.\"\"\"
        # Implementation here
        pass"""

    def _code_analysis_content(self):
        return """from pathlib import Path
from typing import List, Dict
import ast

class CodeAnalyzer:
    def __init__(self, config: Dict):
        self.config = config
        
    def analyze_repositories(self, repo_paths: List[Path]) -> Dict:
        \"\"\"Analyze repositories for patterns and templates.\"\"\"
        # Implementation here
        pass"""

    def _visualization_content(self):
        return """import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict

class Visualizer:
    def __init__(self, config: Dict):
        self.config = config
        
    def visualize_patterns(self, patterns: Dict):
        \"\"\"Create visualizations of discovered patterns.\"\"\"
        # Implementation here
        pass"""

    def _code_generator_content(self):
        return """from typing import Dict
from .parser import Parser
from .transformer import Transformer

class CodeGenerator:
    def __init__(self, config: Dict):
        self.config = config
        self.parser = Parser()
        self.transformer = Transformer()
        
    def generate_code(self, ast) -> str:
        \"\"\"Generate Python code from DSL AST.\"\"\"
        # Implementation here
        pass"""

    def _lexer_content(self):
        return """from typing import List, Tuple
import re

class Token:
    def __init__(self, type: str, value: str, line: int, column: int):
        self.type = type
        self.value = value
        self.line = line
        self.column = column

class Lexer:
    def __init__(self):
        self.tokens = []
        
    def tokenize(self, source: str) -> List[Token]:
        \"\"\"Convert source code into tokens.\"\"\"
        # Implementation here
        pass"""

    def _parser_content(self):
        return """from typing import List
from .lexer import Token

class ASTNode:
    pass

class Parser:
    def __init__(self):
        self.tokens = []
        self.current = 0
        
    def parse(self, tokens: List[Token]) -> ASTNode:
        \"\"\"Parse tokens into an AST.\"\"\"
        # Implementation here
        pass"""

    def _transformer_content(self):
        return """from typing import Dict
from .parser import ASTNode

class Transformer:
    def __init__(self):
        self.symbol_table = {}
        
    def transform(self, ast: ASTNode) -> ASTNode:
        \"\"\"Transform AST for optimization and analysis.\"\"\"
        # Implementation here
        pass"""

    def _utils_content(self):
        return """import yaml
from pathlib import Path
from typing import Dict

def load_config() -> Dict:
    \"\"\"Load configuration from config.yaml.\"\"\"
    config_path = Path('config.yaml')
    with open(config_path) as f:
        return yaml.safe_load(f)"""

    def _test_github_fetcher_content(self):
        return """import pytest
from src.github_fetcher import GitHubFetcher

def test_fetch_repositories():
    config = {'github_token': 'test_token'}
    fetcher = GitHubFetcher(config)
    # Test implementation here
    pass"""

    def _test_code_analysis_content(self):
        return """import pytest
from src.code_analysis import CodeAnalyzer

def test_analyze_repositories():
    config = {}
    analyzer = CodeAnalyzer(config)
    # Test implementation here
    pass"""

    def _test_visualization_content(self):
        return """import pytest
from src.visualization import Visualizer

def test_visualize_patterns():
    config = {}
    visualizer = Visualizer(config)
    # Test implementation here
    pass"""

    def _test_code_generator_content(self):
        return """import pytest
from src.code_generator import CodeGenerator

def test_generate_code():
    config = {}
    generator = CodeGenerator(config)
    # Test implementation here
    pass"""

    def _test_transformer_content(self):
        return """import pytest
from src.transformer import Transformer

def test_transform():
    transformer = Transformer()
    # Test implementation here
    pass"""

    def _sample_dsl_content(self):
        return """# Example DSL code

# Define a macro for nested loops
macro nested_for(outer_seq, inner_seq, body):
    for outer in ${outer_seq}:
        for inner in ${inner_seq}:
            ${body}

# Define a macro for pattern matching
macro match(value, *patterns):
    match ${value}:
        ${patterns}

# Usage example
data = [1, 2, 3]
inner = ['a', 'b']

$nested_for(data, inner,
    print(f"{outer}-{inner}")
)

$match(point,
    case((x, y), print(f"Point: ({x}, {y})")),
    case(_, print("Not a point"))
)"""

    def _examples_readme_content(self):
        return """# PortiaMeta Examples

This directory contains example DSL code snippets demonstrating various features:

- Basic macro usage
- Pattern matching
- Code generation
- Best practices

Each example is documented with expected output and use cases."""

    def _gitignore_content(self):
        return """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/

# IDEs
.idea/
.vscode/
*.swp
*.swo

# Project specific
data/repos/*
data/analysis_results/*
!data/repos/.gitkeep
!data/analysis_results/.gitkeep"""

    def _main_readme_content(self):
        return """# PortiaMeta

A meta-programming system for Python that enables powerful code generation and pattern matching capabilities.

## Features

- Simple and intuitive DSL for meta-programming
- Pattern matching with guards and destructuring
- Code generation from high-level descriptions
- GitHub repository analysis for pattern discovery

## Installation

```bash
pip install -r requirements.txt
```

## Usage

Basic example:

```python
# Define a macro
macro repeat(n, body):
    for _ in range(${n}):
        ${body}

# Use the macro
$repeat(3,
    print("Hello, Meta!")
)
```

## Project Structure

- `/data`: Repository data and analysis results
- `/grammars`: DSL grammar definitions
- `/src`: Core implementation
- `/tests`: Unit tests
- `/examples`: Example DSL code

## Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a new Pull Request"""

    def _requirements_content(self):
        return """# Core dependencies
PyGithub>=1.55
pyyaml>=6.0
pytest>=7.0
matplotlib>=3.5
seaborn>=0.11
black>=22.0
mypy>=0.950
pylint>=2.14
"""

    def _config_content(self):
        config = {
            'github': {
                'token': 'your-token-here',
                'search_queries': [
                    'language:python metaprogramming',
                    'language:python code generation',
                    'language:python pattern matching'
                ],
                'max_repositories': 100
            },
            'analysis': {
                'min_stars': 50,
                'min_pattern_frequency': 5,
                'max_patterns': 1000
            },
            'generation': {
                'output_dir': 'data/generated',
                'template_dir': 'data/templates'
            }
        }
        return yaml.dump(config, default_flow_style=False)

if __name__ == "__main__":
    initializer = ProjectInitializer()
    initializer.create_project_structure()